{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Merge Title II (all years, harmonized) with MANUALLY VALIDATED crosswalk**"
      ],
      "metadata": {
        "id": "Al3mDYpfO6-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================\n",
        "# Block A: Merge Title II (all years, harmonized) with MANUALLY VALIDATED crosswalk\n",
        "# ============================================================\n",
        "\n",
        "TITLEII_ALL_YEARS_FILE = Path(\"TitleII_AllYears_Harmonized_2024Schema.xlsx\")\n",
        "CROSSWALK_VALIDATED_FILE = Path(\"_FINAL_TitleII_with_IPEDS_Matched_UnitID_and_Fuzzy_Details.xlsx\")\n",
        "CROSSWALK_SHEET = \"Cleaned_Final\"\n",
        "OUTPUT_FILE = Path(\"T2_IPEDS_Combined_Data_Matched_Final.xlsx\")\n",
        "\n",
        "STATE_NAME_TO_ABBR = {\n",
        "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
        "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\",\n",
        "    \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
        "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
        "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\",\n",
        "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
        "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\",\n",
        "    \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\",\n",
        "    \"South Carolina\": \"SC\", \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\",\n",
        "    \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\",\n",
        "    \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\",\n",
        "    \"District of Columbia\": \"DC\",\n",
        "    \"American Samoa\": \"AS\", \"Guam\": \"GU\", \"Northern Mariana Islands\": \"MP\",\n",
        "    \"Puerto Rico\": \"PR\", \"Virgin Islands\": \"VI\",\n",
        "    \"Marshall Islands\": \"MH\", \"Micronesia\": \"FM\",\n",
        "}\n",
        "\n",
        "def standardize_name(name):\n",
        "    if pd.isna(name) or name is None:\n",
        "        return \"\"\n",
        "    name = str(name).lower()\n",
        "    name = name.replace(\" at \", \"-\").replace(\" & \", \" and \")\n",
        "    name = re.sub(r\"\\s*-\\s*\", \"-\", name)\n",
        "    name = re.sub(r\"-+\", \"-\", name)\n",
        "    name = name.replace(\" uni \", \" university \").replace(\" univ \", \" university \")\n",
        "    name = name.replace(\" coll \", \" college \").replace(\" clg \", \" college \")\n",
        "    name = name.replace(\" inst \", \" institute \")\n",
        "    name = name.replace(\" tech \", \" technical \")\n",
        "    name = name.replace(\" st \", \" saint \").replace(\" mt \", \" mount \")\n",
        "    name = name.replace(\" dept \", \" department \")\n",
        "    name = name.replace(\" isd \", \" independent school district \")\n",
        "    name = name.replace(\" sch \", \" school \")\n",
        "    name = name.replace(\" of \", \" \")\n",
        "    if name.startswith(\"the \"):\n",
        "        name = name[4:]\n",
        "    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n",
        "    name = re.sub(r\"\\s+\", \" \", name).strip().strip(\"-\")\n",
        "    return name\n",
        "\n",
        "def normalize_key_series(s: pd.Series) -> pd.Series:\n",
        "    return (\n",
        "        s.fillna(\"\")\n",
        "         .astype(str)\n",
        "         .str.replace(\"\\u00A0\", \" \", regex=False)\n",
        "         .str.replace(\"–\", \"-\", regex=False)\n",
        "         .str.replace(\"—\", \"-\", regex=False)\n",
        "         .str.replace(\"’\", \"'\", regex=False)\n",
        "         .str.strip()\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Existence checks\n",
        "# ------------------------------------------------------------\n",
        "for f in [TITLEII_ALL_YEARS_FILE, CROSSWALK_VALIDATED_FILE]:\n",
        "    if not f.exists():\n",
        "        raise FileNotFoundError(f\"Required file not found: {f}. Upload it to /content in Colab.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Load\n",
        "# ------------------------------------------------------------\n",
        "titleii = pd.read_excel(TITLEII_ALL_YEARS_FILE)\n",
        "crosswalk = pd.read_excel(CROSSWALK_VALIDATED_FILE, sheet_name=CROSSWALK_SHEET)\n",
        "\n",
        "print(\"Title II rows:\", len(titleii))\n",
        "print(\"Validated crosswalk rows:\", len(crosswalk))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Validate required raw columns\n",
        "# ------------------------------------------------------------\n",
        "for col in [\"State\", \"Program\", \"ProgramType\"]:\n",
        "    if col not in titleii.columns:\n",
        "        raise KeyError(f\"Title II missing '{col}'. Available: {titleii.columns.tolist()}\")\n",
        "\n",
        "for col in [\"Standardized_State\", \"Program\", \"ProgramType\", \"Matched_UnitID\"]:\n",
        "    if col not in crosswalk.columns:\n",
        "        raise KeyError(f\"Crosswalk missing '{col}'. Available: {crosswalk.columns.tolist()}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Build merge keys (RECOMPUTE, do not trust saved Standardized_Program)\n",
        "# ------------------------------------------------------------\n",
        "titleii[\"TitleII_State_Abbr\"] = titleii[\"State\"].astype(str).str.strip().map(STATE_NAME_TO_ABBR)\n",
        "titleii[\"Standardized_Program\"] = titleii[\"Program\"].astype(str).map(standardize_name)\n",
        "titleii[\"ProgramType\"] = titleii[\"ProgramType\"].astype(str).str.strip()\n",
        "\n",
        "crosswalk[\"Crosswalk_State_Abbr\"] = crosswalk[\"Standardized_State\"].astype(str).str.strip()\n",
        "crosswalk[\"Standardized_Program\"] = crosswalk[\"Program\"].astype(str).map(standardize_name)\n",
        "crosswalk[\"ProgramType\"] = crosswalk[\"ProgramType\"].astype(str).str.strip()\n",
        "\n",
        "unmapped_states = titleii[titleii[\"TitleII_State_Abbr\"].isna()][\"State\"].dropna().unique().tolist()\n",
        "if unmapped_states:\n",
        "    print(\"WARNING: Unmapped Title II states/territories:\", unmapped_states)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Carry-through columns from validated crosswalk\n",
        "# ------------------------------------------------------------\n",
        "columns_to_add = [\n",
        "    \"Matched_UnitID\",\n",
        "    \"Exact_Matched_IPEDS_Name\",\n",
        "    \"Exact_Matched_State\",\n",
        "    \"Match_Source\",\n",
        "    \"Match_Category\",\n",
        "    \"IHE_Title_IV_Funded\",\n",
        "    \"IHE_Based_RPT\",\n",
        "    \"NON_IHE_Based_RPT\",\n",
        "    \"Notes\",\n",
        "]\n",
        "missing_add = [c for c in columns_to_add if c not in crosswalk.columns]\n",
        "if missing_add:\n",
        "    raise KeyError(f\"Crosswalk missing expected columns: {missing_add}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Harden merge keys (both sides)\n",
        "# ------------------------------------------------------------\n",
        "for col in [\"TitleII_State_Abbr\", \"ProgramType\", \"Standardized_Program\"]:\n",
        "    titleii[col] = normalize_key_series(titleii[col])\n",
        "for col in [\"Crosswalk_State_Abbr\", \"ProgramType\", \"Standardized_Program\"]:\n",
        "    crosswalk[col] = normalize_key_series(crosswalk[col])\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Subset + dedupe crosswalk on join keys\n",
        "# ------------------------------------------------------------\n",
        "right_keys = [\"Crosswalk_State_Abbr\", \"ProgramType\", \"Standardized_Program\"]\n",
        "crosswalk_subset = (\n",
        "    crosswalk.loc[:, right_keys + columns_to_add]\n",
        "    .drop_duplicates(subset=right_keys)\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Merge\n",
        "# ------------------------------------------------------------\n",
        "left_keys = [\"TitleII_State_Abbr\", \"ProgramType\", \"Standardized_Program\"]\n",
        "\n",
        "merged = pd.merge(\n",
        "    titleii,\n",
        "    crosswalk_subset,\n",
        "    left_on=left_keys,\n",
        "    right_on=right_keys,\n",
        "    how=\"left\",\n",
        "    suffixes=(\"\", \"_cw\"),\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# POST-MERGE FAILSAFE\n",
        "# ------------------------------------------------------------\n",
        "merged[\"ProgramType\"] = merged[\"ProgramType\"].astype(str).str.strip()\n",
        "\n",
        "EXPECTED_NO_UNITID_PROGRAMTYPES = {\"Alternative, not IHE-based\"}\n",
        "IHE_EXPECTED_PROGRAMTYPES = {\"Traditional\", \"Alternative, IHE-based\"}\n",
        "\n",
        "merged[\"Match_Status\"] = \"Matched\"\n",
        "merged.loc[merged[\"Matched_UnitID\"].isna(), \"Match_Status\"] = \"Unmatched\"\n",
        "merged.loc[\n",
        "    merged[\"ProgramType\"].isin(EXPECTED_NO_UNITID_PROGRAMTYPES) & merged[\"Matched_UnitID\"].isna(),\n",
        "    \"Match_Status\"\n",
        "] = \"Expected blank (non-IHE program)\"\n",
        "\n",
        "needs_review = merged[\n",
        "    (merged[\"ProgramType\"].isin(IHE_EXPECTED_PROGRAMTYPES)) &\n",
        "    (merged[\"Matched_UnitID\"].isna()) &\n",
        "    (\n",
        "        merged[\"IHE_Title_IV_Funded\"].isna() |\n",
        "        merged[\"IHE_Based_RPT\"].isna() |\n",
        "        merged[\"NON_IHE_Based_RPT\"].isna()\n",
        "    )\n",
        "].copy()\n",
        "\n",
        "print(\"\\n--- Post-merge audit ---\")\n",
        "print(\"Expected blank (non-IHE program) rows:\", (merged[\"Match_Status\"] == \"Expected blank (non-IHE program)\").sum())\n",
        "print(\"Needs review (IHE-expected, still unmatched) rows:\", len(needs_review))\n",
        "\n",
        "needs_review.to_csv(\"audit_needs_review_ihe_expected.csv\", index=False)\n",
        "\n",
        "print(\"Final rows:\", len(merged))\n",
        "print(\"Matched UnitIDs:\", merged[\"Matched_UnitID\"].notna().sum())\n",
        "print(\"Unmatched rows:\", merged[\"Matched_UnitID\"].isna().sum())\n",
        "\n",
        "merged.to_excel(OUTPUT_FILE, index=False)\n",
        "print(f\"Saved merged file → {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "id": "8mP-JzZAPB3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Post-merge Derivations & Final Column Ordering**"
      ],
      "metadata": {
        "id": "dI8LXHz_n9MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================\n",
        "# Post-merge derivations & final column ordering\n",
        "# ============================================================\n",
        "\n",
        "INPUT_FILE = \"T2_IPEDS_Combined_Data_Matched_Final.xlsx\"\n",
        "OUTPUT_FILE = \"T2_IPEDS_Combined_Data_Final_Updated_Reordered.xlsx\"\n",
        "\n",
        "df = pd.read_excel(INPUT_FILE)\n",
        "\n",
        "print(\"Loaded merged dataset:\", len(df), \"rows\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Adjust TotalEnrollment to account for post-2019 definition change\n",
        "# ------------------------------------------------------------\n",
        "df[\"ReportYear\"] = df[\"ReportYear\"].astype(int)\n",
        "\n",
        "df[\"TotalEnrollment_Adj\"] = np.where(\n",
        "    (df[\"ReportYear\"] >= 2012) & (df[\"ReportYear\"] <= 2019),\n",
        "    df[\"TotalEnrollment\"],\n",
        "    df[\"TotalEnrollment\"] - df[\"CompletersCurrent\"]\n",
        ")\n",
        "\n",
        "# Optional safety check\n",
        "negatives = df[df[\"TotalEnrollment_Adj\"] < 0]\n",
        "if not negatives.empty:\n",
        "    print(\"WARNING: Negative adjusted enrollment values detected:\")\n",
        "    print(negatives[[\"ReportYear\", \"Program\", \"TotalEnrollment\", \"CompletersCurrent\", \"TotalEnrollment_Adj\"]].head())\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Define authoritative column order\n",
        "# ------------------------------------------------------------\n",
        "ordered_columns = [\n",
        "    'ReportYear',\n",
        "    'State', 'TitleII_State_Abbr',\n",
        "    'ProgramCode',\n",
        "    'Program',\n",
        "    'ProgramType',\n",
        "    'SchoolNeeds',\n",
        "    'StateLocalNeeds',\n",
        "    'LocalityTrn',\n",
        "    'SpecEdCore',\n",
        "    'GenEdDisabilities',\n",
        "    'GenEdLEP',\n",
        "    'GenEdLowInc',\n",
        "    'GrantMajors',\n",
        "    'TotalEnrollment',\n",
        "    'TotalEnrollment_Adj',\n",
        "    'CompletersCurrent',\n",
        "    'AsianCompleters',\n",
        "    'AsianEnrollment',\n",
        "    'BlackCompleters',\n",
        "    'BlackEnrollment',\n",
        "    'HispanicCompleters',\n",
        "    'HispanicEnrollment',\n",
        "    'IndianCompleters',\n",
        "    'IndianEnrollment',\n",
        "    'IslanderCompleters',\n",
        "    'IslanderEnrollment',\n",
        "    'FemaleCompleters',\n",
        "    'FemaleEnrollment',\n",
        "    'MaleCompleters',\n",
        "    'MaleEnrollment',\n",
        "    'MultiRacialCompleters',\n",
        "    'MultiRacialEnrollment',\n",
        "    'NonReportGenderCompleters',\n",
        "    'NonReportGenderEnrollment',\n",
        "    'NonReportRaceEthCompleters',\n",
        "    'NonReportRaceEthEnrollment',\n",
        "    'OtherGenderCompleters',\n",
        "    'OtherGenderEnrollment',\n",
        "    'WhiteCompleters',\n",
        "    'WhiteEnrollment',\n",
        "    'PGMinGPAEntry',\n",
        "    'PGMinGPAExit',\n",
        "    'PGPrograms',\n",
        "    'SCEAvgHrsFor_StdntTch',\n",
        "    'SCEAvgHrsPrior_StdntTch',\n",
        "    'SCEAvgHrsPrior_TeachRcd',\n",
        "    'SCENumAdjunctIHE',\n",
        "    'SCENumCoopTeachK12',\n",
        "    'SuperFTEFaculty',\n",
        "    'SuperStudents',\n",
        "    'TotalNumPrepPrgs',\n",
        "    'UGMinGPAEntry',\n",
        "    'UGMinGPAExit',\n",
        "    'UGPrograms',\n",
        "    'AssuranceComments',\n",
        "    # Matching / provenance fields (kept at end by design)\n",
        "    'Standardized_Program',\n",
        "    'Matched_UnitID',\n",
        "    'Exact_Matched_IPEDS_Name',\n",
        "    'Exact_Matched_State',\n",
        "    'Match_Source',\n",
        "    'Match_Category',\n",
        "    'IHE_Title_IV_Funded',\n",
        "    'IHE_Based_RPT',\n",
        "    'NON_IHE_Based_RPT',\n",
        "    'Notes'\n",
        "]\n",
        "\n",
        "missing_cols = [c for c in ordered_columns if c not in df.columns]\n",
        "if missing_cols:\n",
        "    raise KeyError(f\"Missing expected columns before reordering: {missing_cols}\")\n",
        "\n",
        "df = df[ordered_columns]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Export final analysis-ready dataset\n",
        "# ------------------------------------------------------------\n",
        "df.to_excel(OUTPUT_FILE, index=False)\n",
        "\n",
        "print(\"Final dataset saved to:\", OUTPUT_FILE)\n",
        "print(\"Final column count:\", len(df.columns))"
      ],
      "metadata": {
        "id": "1UnoZu7xLPEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
